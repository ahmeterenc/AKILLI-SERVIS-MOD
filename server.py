import sys
import zmq
import tkinter as tk
from PIL import Image, ImageTk
import cv2
import numpy as np
import threading
import psutil
import os
import time
import simpleaudio as sa
import torch
from queue import Queue

# ========== MODEL ==========
TARGET_CLASSES = {
    0: "insan",
    2: "arac",
    16: "kedi",
    17: "kopek"
}

# Yerel model dosyasÄ±nÄ± kullan
try:
    from ultralytics import YOLO
    model = YOLO('yolov5s.pt')
    print("âœ… Model baÅŸarÄ±yla yÃ¼klendi (YOLO)")
except ImportError:
    # Fallback: torch ile yerel model yÃ¼kle
    model = torch.hub.load('ultralytics/yolov5', 'custom', path='yolov5s.pt', force_reload=True)
    model.to("cpu").eval()
    print("âœ… Model baÅŸarÄ±yla yÃ¼klendi (torch)")
except Exception as e:
    print(f"âŒ Model yÃ¼kleme hatasÄ±: {e}")
    sys.exit(1)

# ========== ZMQ AyarlarÄ± ==========
context = zmq.Context()
socket = context.socket(zmq.PULL)

# BaÄŸlantÄ± ayarlarÄ± - Pi 4 iÃ§in optimize
socket.setsockopt(zmq.RCVHWM, 100)  # Receive buffer
socket.setsockopt(zmq.RCVTIMEO, 1000)  # 1 saniye timeout
socket.bind("tcp://*:5555")
print("ðŸŒ ZMQ Server baÅŸlatÄ±ldÄ±: tcp://*:5555")

latest_frames = {
    "cam1": None,
    "cam2": None,
    "cam3": None
}

alerts = {
    "cam1": "",
    "cam2": "",
    "cam3": ""
}

annotated_frames = {
    "cam1": None,
    "cam2": None,
    "cam3": None
}

# ========== Bellek Kontrol ==========
def print_memory_usage():
    process = psutil.Process(os.getpid())
    mem = process.memory_info().rss / 1024 ** 2
    print(f"ðŸ“Š RAM KullanÄ±mÄ±: {mem:.2f} MB")
    if mem > 2048:
        print("âŒ RAM kullanÄ±mÄ± 2 GB'Ä± aÅŸtÄ±. Uygulama sonlandÄ±rÄ±lÄ±yor...")
        sys.exit(1)

# ========== UyarÄ± Sesi ==========
def play_alert():
    try:
        wave_obj = sa.WaveObject.from_wave_file("alert.wav")
        wave_obj.play()
    except Exception as e:
        print(f"[Ses HatasÄ±] {e}")

# ========== Frame KuyruÄŸu ==========
frame_queue = Queue(maxsize=10)

def analyze_worker():
    while True:
        cam_name, frame = frame_queue.get()
        try:
            frame_resized = cv2.resize(frame, (320, 240))
            
            # Model ile tahmin yap
            results = model(frame_resized)
            
            found = False
            
            # YOLO v8 (ultralytics) formatÄ± kontrolÃ¼
            if hasattr(results, '__iter__') and len(results) > 0:
                result = results[0]
                if hasattr(result, 'boxes') and result.boxes is not None:
                    # YOLO v8 formatÄ±
                    for box in result.boxes:
                        cls_id = int(box.cls[0])
                        if cls_id in TARGET_CLASSES:
                            found = True
                            x1, y1, x2, y2 = map(int, box.xyxy[0])
                            conf = float(box.conf[0])
                            label = f"{TARGET_CLASSES[cls_id]} {conf:.2f}"
                            cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 0, 255), 2)
                            cv2.putText(frame_resized, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)
                else:
                    # YOLO v5 formatÄ± fallback
                    for *xyxy, conf, cls in results.xyxy[0]:
                        cls_id = int(cls)
                        if cls_id in TARGET_CLASSES:
                            found = True
                            x1, y1, x2, y2 = map(int, xyxy)
                            label = f"{TARGET_CLASSES[cls_id]} {conf:.2f}"
                            cv2.rectangle(frame_resized, (x1, y1), (x2, y2), (0, 0, 255), 2)
                            cv2.putText(frame_resized, label, (x1, y1 - 5), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)

            alerts[cam_name] = "ðŸš¨ TESPÄ°T VAR" if found else ""
            annotated_frames[cam_name] = frame_resized.copy()
            
            if found:
                threading.Thread(target=play_alert, daemon=True).start()

        except Exception as e:
            print(f"[Analyze Hata] {e}")
        frame_queue.task_done()

# ========== ZMQ AlÄ±cÄ± ==========
def zmq_receiver():
    print("ðŸ“¡ ZMQ alÄ±cÄ± baÅŸlatÄ±ldÄ±...")
    consecutive_errors = 0
    max_errors = 20
    
    while consecutive_errors < max_errors:
        try:
            # Timeout ile mesaj al
            message = socket.recv_json(zmq.NOBLOCK)
            consecutive_errors = 0  # BaÅŸarÄ±lÄ± alÄ±m
            
            cam_name = message.get("cam", "unknown")
            img_hex = message.get("img", "")
            
            if not img_hex:
                print(f"âš ï¸ BoÅŸ frame alÄ±ndÄ±: {cam_name}")
                continue
                
            try:
                img_bytes = bytes.fromhex(img_hex)
                npimg = np.frombuffer(img_bytes, dtype=np.uint8)
                frame = cv2.imdecode(npimg, cv2.IMREAD_COLOR)

                if frame is not None and cam_name in latest_frames:
                    latest_frames[cam_name] = frame
                    print(f"ðŸ“¸ Frame alÄ±ndÄ±: {cam_name} ({frame.shape})")
                    
                    # Analiz kuyruÄŸuna ekle
                    if not frame_queue.full():
                        frame_queue.put((cam_name, frame))
                    else:
                        print(f"âš ï¸ Analiz kuyruÄŸu dolu: {cam_name}")
                else:
                    print(f"âŒ Frame decode edilemedi: {cam_name}")
                    
            except ValueError as e:
                print(f"âŒ Hex decode hatasÄ± ({cam_name}): {e}")
            except Exception as e:
                print(f"âŒ Frame iÅŸleme hatasÄ± ({cam_name}): {e}")
                
        except zmq.Again:
            # Timeout - normal durum
            time.sleep(0.01)  # KÄ±sa bekleme
        except zmq.ZMQError as e:
            consecutive_errors += 1
            print(f"âŒ ZMQ hatasÄ± ({consecutive_errors}/{max_errors}): {e}")
            time.sleep(0.1)
        except Exception as e:
            consecutive_errors += 1
            print(f"âŒ Genel alÄ±m hatasÄ± ({consecutive_errors}/{max_errors}): {e}")
            time.sleep(0.5)

    print("ðŸ’€ ZMQ alÄ±cÄ± Ã§ok fazla hata aldÄ±, sonlandÄ±rÄ±lÄ±yor")
    socket.close()
    context.term()

# ========== Tkinter ArayÃ¼z ==========
class CameraViewer:
    def __init__(self, window):
        self.window = window
        self.window.title("ðŸŽ¥ Kamera Takip + Tespit Sistemi")

        self.labels = {}
        self.alerts = {}
        for i, cam in enumerate(["cam1", "cam2", "cam3"]):
            frame = tk.Frame(window)
            frame.grid(row=i // 2, column=i % 2, padx=10, pady=10)

            label = tk.Label(frame)
            label.pack()
            self.labels[cam] = label

            alert_label = tk.Label(frame, text="", fg="red", font=("Helvetica", 12, "bold"))
            alert_label.pack()
            self.alerts[cam] = alert_label

        self.update_images()

    def update_images(self):
        for cam_name, frame in annotated_frames.items():
            if frame is not None:
                img = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
                img = Image.fromarray(img)
                img = img.resize((320, 240), Image.BILINEAR)
                tk_img = ImageTk.PhotoImage(img)
                self.labels[cam_name].config(image=tk_img)
                self.labels[cam_name].image = tk_img
                self.alerts[cam_name].config(text=alerts[cam_name])

        print_memory_usage()
        self.window.after(100, self.update_images)

# ========== BaÅŸlat ==========
if __name__ == "__main__":
    threading.Thread(target=analyze_worker, daemon=True).start()
    threading.Thread(target=zmq_receiver, daemon=True).start()
    root = tk.Tk()
    app = CameraViewer(root)
    root.mainloop()
